{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fec154c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa7cf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('dataset/kanye/original/ye.jpg')\n",
    "plt.imshow(img)\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#plt.imshow(gray, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd720304",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "\n",
    "(x,y,w,h) = faces[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58ce917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cropped_img(path):\n",
    "    img = cv2.imread(path,3)\n",
    "    b,g,r = cv2.split(img)\n",
    "    img = cv2.merge([r,g,b])\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    if len(faces)>0:\n",
    "        (x,y,w,h) = faces[0]\n",
    "        return img[y:y+h, x:x+w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdd583f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rappers = 'kanye drake jayz eminem nicki'.split()\n",
    "for rapper in rappers:\n",
    "    folder = os.listdir(f'dataset/{rapper}/original')\n",
    "    if '.DS_Store' in folder:\n",
    "        os.remove(os.path.join(f'dataset/{rapper}/original','.DS_Store'))\n",
    "        print(f'removed ds store in {rapper}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e45627",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rapper in rappers:\n",
    "    for i, file in enumerate(os.listdir(f'dataset/{rapper}/original')):\n",
    "        fullpath = os.path.join(f'dataset/{rapper}/original', file)\n",
    "        cropped_image = get_cropped_img(fullpath)\n",
    "        if isinstance(cropped_image, numpy.ndarray):\n",
    "            number = str(i).zfill(2)\n",
    "            plt.imsave(f'dataset/{rapper}/cropped/{number}.png',cropped_image)\n",
    "            print(f'saved to dataset/{rapper}/cropped/{number}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa77315b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pywt\n",
    "import cv2    \n",
    "\n",
    "def w2d(img, mode='haar', level=1):\n",
    "    imArray = img\n",
    "    #Datatype conversions\n",
    "    #convert to grayscale\n",
    "    imArray = cv2.cvtColor( imArray,cv2.COLOR_RGB2GRAY )\n",
    "    #convert to float\n",
    "    imArray =  np.float32(imArray)   \n",
    "    imArray /= 255;\n",
    "    # compute coefficients \n",
    "    coeffs=pywt.wavedec2(imArray, mode, level=level)\n",
    "\n",
    "    #Process Coefficients\n",
    "    coeffs_H=list(coeffs)  \n",
    "    coeffs_H[0] *= 0;  \n",
    "\n",
    "    # reconstruction\n",
    "    imArray_H=pywt.waverec2(coeffs_H, mode);\n",
    "    imArray_H *= 255;\n",
    "    imArray_H =  np.uint8(imArray_H)\n",
    "\n",
    "    return imArray_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f97487db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed ds store in kanye cropped folder\n",
      "removed ds store in drake cropped folder\n",
      "removed ds store in jayz cropped folder\n",
      "removed ds store in eminem cropped folder\n",
      "removed ds store in nicki cropped folder\n"
     ]
    }
   ],
   "source": [
    "rappers = 'kanye drake jayz eminem nicki'.split()\n",
    "for rapper in rappers:\n",
    "    folder = os.listdir(f'dataset/{rapper}/cropped')\n",
    "    if '.DS_Store' in folder:\n",
    "        os.remove(os.path.join(f'dataset/{rapper}/cropped','.DS_Store'))\n",
    "        print(f'removed ds store in {rapper} cropped folder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "42ee7ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/kanye/cropped/62.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/76.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/89.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/48.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/49.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/61.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/59.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/70.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/64.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/66.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/73.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/98.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/101.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/14.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/00.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/28.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/29.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/03.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/16.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/02.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/06.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/12.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/13.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/04.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/10.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/38.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/09.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/08.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/34.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/36.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/23.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/27.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/33.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/30.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/25.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/19.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/95.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/42.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/57.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/82.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/41.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/55.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/54.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/97.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/83.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/87.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/93.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/78.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/44.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/51.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/86.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/90.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/53.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/47.png\n",
      "\t(4096, 1)\n",
      "dataset/kanye/cropped/52.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/63.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/62.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/60.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/48.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/49.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/61.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/59.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/65.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/64.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/58.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/14.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/00.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/28.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/29.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/03.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/17.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/16.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/02.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/06.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/12.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/13.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/07.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/39.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/11.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/05.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/04.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/38.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/35.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/21.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/09.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/08.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/20.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/36.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/37.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/23.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/33.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/32.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/18.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/30.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/24.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/25.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/31.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/56.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/42.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/43.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/57.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/41.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/55.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/54.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/40.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/44.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/50.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/53.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/46.png\n",
      "\t(4096, 1)\n",
      "dataset/drake/cropped/52.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/77.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/63.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/62.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/76.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/60.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/74.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/48.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/49.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/61.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/59.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/65.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/71.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/70.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/64.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/58.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/66.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/67.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/73.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/14.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/28.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/01.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/15.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/03.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/16.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/02.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/06.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/12.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/13.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/39.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/11.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/10.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/38.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/35.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/21.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/09.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/08.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/20.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/22.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/36.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/37.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/23.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/27.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/33.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/32.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/26.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/18.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/24.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/25.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/31.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/19.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/81.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/56.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/42.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/43.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/57.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/82.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/41.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/55.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/69.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/68.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/54.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/40.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/83.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/78.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/44.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/51.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/45.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/84.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/53.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/47.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/46.png\n",
      "\t(4096, 1)\n",
      "dataset/jayz/cropped/52.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/88.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/77.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/63.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/62.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/76.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/89.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/74.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/48.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/75.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/61.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/59.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/64.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/99.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/72.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/66.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/00.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/28.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/01.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/100.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/16.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/02.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/103.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/113.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/06.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/12.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/07.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/110.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/05.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/04.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/111.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/35.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/21.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/34.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/22.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/36.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/37.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/27.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/18.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/25.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/31.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/42.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/43.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/94.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/82.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/96.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/55.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/68.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/54.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/97.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/93.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/50.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/51.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/45.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/84.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/53.png\n",
      "\t(4096, 1)\n",
      "dataset/eminem/cropped/85.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/63.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/62.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/60.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/48.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/59.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/58.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/00.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/29.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/01.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/15.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/03.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/17.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/16.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/02.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/06.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/12.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/13.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/07.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/39.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/11.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/05.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/10.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/38.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/21.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/09.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/20.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/34.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/22.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/36.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/27.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/32.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/26.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/19.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/42.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/43.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/57.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/41.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/55.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/40.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/45.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/53.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/46.png\n",
      "\t(4096, 1)\n",
      "dataset/nicki/cropped/52.png\n",
      "\t(4096, 1)\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for r, rapper in enumerate(rappers):\n",
    "    folder = f'dataset/{rapper}/cropped'\n",
    "    for file in os.listdir(folder):\n",
    "        fullpath = os.path.join(folder,file)\n",
    "        print(fullpath)\n",
    "        img = cv2.imread(fullpath)\n",
    "        scalled_raw_img = cv2.resize(img, (32, 32))\n",
    "        img_har = w2d(img,'db1',5)\n",
    "        scalled_img_har = cv2.resize(img_har, (32, 32))\n",
    "        combined_img = np.vstack((scalled_raw_img.reshape(32*32*3,1),scalled_img_har.reshape(32*32,1)))\n",
    "        X.append(combined_img)\n",
    "        print(f'\\t{combined_img.shape}')\n",
    "        y.append(r)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08f889f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#time for the real AI\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "69e49e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7464788732394366"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "shape = X.shape\n",
    "X = X.reshape(shape[0],shape[1])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "X_train = np.array(X_train)\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('svc', SVC(kernel = 'rbf', C = 10))])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "85c27327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.64      0.67        11\n",
      "           1       0.80      0.80      0.80        15\n",
      "           2       0.73      0.84      0.78        19\n",
      "           3       0.72      0.68      0.70        19\n",
      "           4       0.83      0.71      0.77         7\n",
      "\n",
      "    accuracy                           0.75        71\n",
      "   macro avg       0.76      0.74      0.74        71\n",
      "weighted avg       0.75      0.75      0.75        71\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pipe.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb99b5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a009c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'svm': {\n",
    "        'model': svm.SVC(gamma='auto',probability=True),\n",
    "        'params' : {\n",
    "            'svc__C': [1,10,100,1000],\n",
    "            'svc__kernel': ['rbf','linear']\n",
    "        }  \n",
    "    },\n",
    "    'random_forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params' : {\n",
    "            'randomforestclassifier__n_estimators': [1,5,10]\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression' : {\n",
    "        'model': LogisticRegression(solver='liblinear',multi_class='auto'),\n",
    "        'params': {\n",
    "            'logisticregression__C': [1,5,10]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "87fe58d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>{'svc__C': 1, 'svc__kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.647619</td>\n",
       "      <td>{'randomforestclassifier__n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>{'logisticregression__C': 10}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  best_score  \\\n",
       "0                  svm    0.833333   \n",
       "1        random_forest    0.647619   \n",
       "2  logistic_regression    0.833333   \n",
       "\n",
       "                                    best_params  \n",
       "0        {'svc__C': 1, 'svc__kernel': 'linear'}  \n",
       "1  {'randomforestclassifier__n_estimators': 10}  \n",
       "2                 {'logisticregression__C': 10}  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "best_estimators = {}\n",
    "import pandas as pd\n",
    "for algo, mp in model_params.items():\n",
    "    pipe = make_pipeline(StandardScaler(), mp['model'])\n",
    "    clf =  GridSearchCV(pipe, mp['params'], cv=5, return_train_score=False)\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores.append({\n",
    "        'model': algo,\n",
    "        'best_score': clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    })\n",
    "    best_estimators[algo] = clf.best_estimator_\n",
    "    \n",
    "df = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8d5cba6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svm': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('svc',\n",
       "                  SVC(C=1, gamma='auto', kernel='linear', probability=True))]),\n",
       " 'random_forest': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('randomforestclassifier',\n",
       "                  RandomForestClassifier(n_estimators=10))]),\n",
       " 'logistic_regression': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('logisticregression',\n",
       "                  LogisticRegression(C=10, solver='liblinear'))])}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e72858dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7887323943661971"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators['svm'].score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9dd24b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6197183098591549"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators['random_forest'].score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "98bcc4cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8169014084507042"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators['logistic_regression'].score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d2b646c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf = best_estimators['svm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "022d3c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8,  1,  2,  0,  0],\n",
       "       [ 1, 12,  0,  2,  0],\n",
       "       [ 0,  0, 14,  3,  2],\n",
       "       [ 2,  1,  1, 15,  0],\n",
       "       [ 0,  0,  0,  0,  7]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, best_clf.predict(X_test))\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b556eec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(69.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(cm, annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dfa69f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in /Users/abelardoriojas/opt/anaconda3/lib/python3.8/site-packages (1.0.1)\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['saved_model.pkl']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install joblib\n",
    "import joblib \n",
    "# Save the model as a pickle in a file \n",
    "joblib.dump(best_clf, 'saved_model.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2dbc25e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = {'kanye': 0,\n",
    " 'drake': 1,\n",
    " 'jayz': 2,\n",
    " 'eminem': 3,\n",
    " 'nicki': 4}\n",
    "\n",
    "import json\n",
    "with open(\"class_dictionary.json\",\"w\") as f:\n",
    "    f.write(json.dumps(class_dict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
